<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Running on GPUs · ITensors.jl</title><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script><link href="assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="index.html"><img src="assets/logo.png" alt="ITensors.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="index.html">ITensors.jl</a></span></div><form class="docs-search" action="search.html"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="index.html">Introduction</a></li><li><span class="tocitem">Getting Started with ITensor</span><ul><li><a class="tocitem" href="getting_started/Installing.html">Installing Julia and ITensor</a></li><li><a class="tocitem" href="getting_started/RunningCodes.html">Running ITensor and Julia Codes</a></li><li><a class="tocitem" href="getting_started/DebugChecks.html">Enabling Debug Checks</a></li><li><a class="tocitem" href="getting_started/NextSteps.html">Next Steps</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="tutorials/DMRG.html">DMRG</a></li><li><a class="tocitem" href="tutorials/QN_DMRG.html">Quantum Number Conserving DMRG</a></li><li><a class="tocitem" href="tutorials/MPSTimeEvolution.html">MPS Time Evolution</a></li></ul></li><li><span class="tocitem">Code Examples</span><ul><li><a class="tocitem" href="examples/ITensor.html">ITensor Examples</a></li><li><a class="tocitem" href="examples/MPSandMPO.html">MPS and MPO Examples</a></li><li><a class="tocitem" href="examples/DMRG.html">DMRG Examples</a></li><li><a class="tocitem" href="examples/Physics.html">Physics (SiteType) System Examples</a></li></ul></li><li><span class="tocitem">Documentation</span><ul><li><a class="tocitem" href="IndexType.html">Index</a></li><li><a class="tocitem" href="IndexSetType.html">Index collections</a></li><li><a class="tocitem" href="ITensorType.html">ITensor</a></li><li><a class="tocitem" href="MPSandMPO.html">MPS and MPO</a></li><li><a class="tocitem" href="QN.html">QN</a></li><li><a class="tocitem" href="SiteType.html">SiteType and op, state, val functions</a></li><li><a class="tocitem" href="IncludedSiteTypes.html">SiteTypes Included with ITensor</a></li><li><input class="collapse-toggle" id="menuitem-5-8" type="checkbox"/><label class="tocitem" for="menuitem-5-8"><span class="docs-label">DMRG</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="DMRG.html">DMRG</a></li><li><a class="tocitem" href="Sweeps.html">Sweeps</a></li><li><a class="tocitem" href="ProjMPO.html">ProjMPO</a></li><li><a class="tocitem" href="ProjMPOSum.html">ProjMPOSum</a></li><li><a class="tocitem" href="Observer.html">Observer System for DMRG</a></li><li><a class="tocitem" href="DMRGObserver.html">DMRGObserver</a></li></ul></li><li><a class="tocitem" href="OpSum.html">OpSum</a></li></ul></li><li><span class="tocitem">Frequently Asked Questions</span><ul><li><a class="tocitem" href="faq/JuliaAndCpp.html">Programming Language (Julia, C++, ...) FAQs</a></li><li><a class="tocitem" href="faq/DMRG.html">DMRG FAQs</a></li><li><a class="tocitem" href="faq/QN.html">Quantum Number (QN) FAQs</a></li><li><a class="tocitem" href="faq/Development.html">ITensor Development FAQs</a></li><li><a class="tocitem" href="faq/RelationshipToOtherLibraries.html">Relationship of ITensor to other tensor libraries FAQs</a></li><li><a class="tocitem" href="faq/JuliaPkg.html">Julia Package Manager FAQs</a></li><li><a class="tocitem" href="faq/HPC.html">High-Performance Computing FAQs</a></li></ul></li><li><span class="tocitem">Upgrade guides</span><ul><li><a class="tocitem" href="UpgradeGuide_0.1_to_0.2.html">Upgrading from 0.1 to 0.2</a></li></ul></li><li><a class="tocitem" href="Einsum.html">ITensor indices and Einstein notation</a></li><li><span class="tocitem">Advanced Usage Guide</span><ul><li><a class="tocitem" href="AdvancedUsageGuide.html">Advanced Usage Guide</a></li><li><a class="tocitem" href="Multithreading.html">Multithreading</a></li><li class="is-active"><a class="tocitem" href="RunningOnGPUs.html">Running on GPUs</a><ul class="internal"><li><a class="tocitem" href="#GPU-backends"><span>GPU backends</span></a></li></ul></li><li><a class="tocitem" href="QNTricks.html">Symmetric (QN conserving) tensors: background and usage</a></li><li><a class="tocitem" href="CodeTiming.html">Timing and profiling</a></li><li><a class="tocitem" href="ContractionSequenceOptimization.html">Contraction sequence optimization</a></li><li><a class="tocitem" href="HDF5FileFormats.html">HDF5 File Formats</a></li></ul></li><li><a class="tocitem" href="DeveloperGuide.html">Developer Guide</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Advanced Usage Guide</a></li><li class="is-active"><a href="RunningOnGPUs.html">Running on GPUs</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="RunningOnGPUs.html">Running on GPUs</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/ITensor/ITensors.jl/blob/main/docs/src/RunningOnGPUs.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Running-on-GPUs"><a class="docs-heading-anchor" href="#Running-on-GPUs">Running on GPUs</a><a id="Running-on-GPUs-1"></a><a class="docs-heading-anchor-permalink" href="#Running-on-GPUs" title="Permalink"></a></h1><p>ITensor provides package extensions for running tensor operations on a variety of GPU backends. You can activate a backend by loading the appropriate Julia GPU package alongside ITensors.jl and moving your tensors and/or tensor networks to an available GPU using that package&#39;s provided conversion functions.</p><p>For example, you can load CUDA.jl to perform tensor operations on NVIDIA GPUs or Metal.jl to perform tensor operations on Apple GPUs:</p><pre><code class="language-julia hljs">using ITensors

i, j, k = Index.((2, 2, 2))
A = random_itensor(i, j)
B = random_itensor(j, k)

# Perform tensor operations on CPU
A * B

###########################################
using CUDA # This will trigger the loading of `NDTensorsCUDAExt` in the background

# Move tensors to NVIDIA GPU
Acu = cu(A)
Bcu = cu(B)

# Perform tensor operations on NVIDIA GPU
Acu * Bcu

###########################################
using Metal # This will trigger the loading of `NDTensorsMetalExt` in the background

# Move tensors to Apple GPU
Amtl = mtl(A)
Bmtl = mtl(B)

# Perform tensor operations on Apple GPU
Amtl * Bmtl</code></pre><p>Note that we highly recommend using these new package extensions as opposed to <a href="https://github.com/ITensor/ITensorGPU.jl">ITensorGPU.jl</a>, which is ITensor&#39;s previous CUDA backend. The package extensions are better integrated into the main library so are more reliable and better supported right now. We plan to deprecate <code>ITensorGPU.jl</code> in the future.</p><h2 id="GPU-backends"><a class="docs-heading-anchor" href="#GPU-backends">GPU backends</a><a id="GPU-backends-1"></a><a class="docs-heading-anchor-permalink" href="#GPU-backends" title="Permalink"></a></h2><p>ITensor currently provides package extensions for the following GPU backends:</p><ul><li><a href="https://github.com/JuliaGPU/CUDA.jl">CUDA.jl</a> (NVIDIA GPUs)</li><li><a href="https://github.com/JuliaGPU/CUDA.jl/tree/master/lib/cutensor">cuTENSOR.jl</a> (<code>CUDA.jl</code> extension providing accelerated binary tensor contractions)</li><li><a href="https://github.com/JuliaGPU/Metal.jl">Metal.jl</a> (Apple GPUs)</li><li><a href="https://github.com/JuliaGPU/AMDGPU.jl">AMDGPU.jl</a> (AMD GPUs)</li></ul><p>Our goal is to support all GPU backends which are supported by the <a href="https://juliagpu.org">JuliaGPU organization</a>.</p><p>Notice that <code>cuTENSOR.jl</code> is an extension of <code>CUDA.jl</code> that provides new functionality for accelerated binary tensor contractions. If the <code>cuTENSOR.jl</code> library is loaded then ITensors with <code>CuArray</code> data are contracted using <code>cuTENSOR</code> and if the <code>cuTENSOR.jl</code> library is not loaded but <code>CUDA.jl</code> is loaded then binary tensor contractions are mapped to a matrix multiplication and performed using <code>cuBLAS</code>.</p><p>Some important caveats to keep in mind related to the ITensor GPU backends are:</p><ul><li>only dense tensor operations are well supported right now. Block sparse operations (which arise when QN conservation is enabled) are under active development and either may not work or may be slower than their CPU counterparts,</li><li>certain GPU backends do not have native support for certain matrix decompositions like <code>svd</code>, <code>eigen</code>, and <code>qr</code> in which case we will perform those operations on CPU. If your calculation is dominated by those operations, there likely is no advantage to running it on GPU right now. CUDA generally has good support for native matrix decompositions, while Metal and AMD have more limited support right now, and</li><li>single precision (<code>Float32</code>) calculations are generally fastest on GPU.</li></ul><p>The table below summarizes each backend&#39;s current capabilities.</p><table><tr><th style="text-align: right"></th><th style="text-align: right">CUDA</th><th style="text-align: right">cuTENSOR</th><th style="text-align: right">ROCm</th><th style="text-align: right">Metal</th><th style="text-align: right">oneAPI</th></tr><tr><td style="text-align: right">Contractions (dense)</td><td style="text-align: right">✓ (cuBLAS)</td><td style="text-align: right">✓</td><td style="text-align: right">✓</td><td style="text-align: right">✓</td><td style="text-align: right">N/A<sup class="footnote-reference"><a id="citeref-oneapi" href="#footnote-oneapi">[oneapi]</a></sup></td></tr><tr><td style="text-align: right">QR (dense)</td><td style="text-align: right">✓ (cuSOLVER)</td><td style="text-align: right">✓ (cuSOLVER)</td><td style="text-align: right">On CPU<sup class="footnote-reference"><a id="citeref-linalg" href="#footnote-linalg">[linalg]</a></sup></td><td style="text-align: right">On CPU<sup class="footnote-reference"><a id="citeref-linalg" href="#footnote-linalg">[linalg]</a></sup></td><td style="text-align: right">N/A<sup class="footnote-reference"><a id="citeref-oneapi" href="#footnote-oneapi">[oneapi]</a></sup></td></tr><tr><td style="text-align: right">SVD (dense)</td><td style="text-align: right">✓ (cuSOLVER)</td><td style="text-align: right">✓ (cuSOLVER)</td><td style="text-align: right">On CPU<sup class="footnote-reference"><a id="citeref-linalg" href="#footnote-linalg">[linalg]</a></sup></td><td style="text-align: right">On CPU<sup class="footnote-reference"><a id="citeref-linalg" href="#footnote-linalg">[linalg]</a></sup></td><td style="text-align: right">N/A<sup class="footnote-reference"><a id="citeref-oneapi" href="#footnote-oneapi">[oneapi]</a></sup></td></tr><tr><td style="text-align: right">Eigendecomposition (dense)</td><td style="text-align: right">✓ (cuSOLVER)</td><td style="text-align: right">✓ (cuSOLVER)</td><td style="text-align: right">On CPU<sup class="footnote-reference"><a id="citeref-linalg" href="#footnote-linalg">[linalg]</a></sup></td><td style="text-align: right">On CPU<sup class="footnote-reference"><a id="citeref-linalg" href="#footnote-linalg">[linalg]</a></sup></td><td style="text-align: right">N/A<sup class="footnote-reference"><a id="citeref-oneapi" href="#footnote-oneapi">[oneapi]</a></sup></td></tr><tr><td style="text-align: right">Double precision (<code>Float64</code>)</td><td style="text-align: right">✓</td><td style="text-align: right">✓</td><td style="text-align: right">✓</td><td style="text-align: right">N/A<sup class="footnote-reference"><a id="citeref-metal" href="#footnote-metal">[metal]</a></sup></td><td style="text-align: right">N/A<sup class="footnote-reference"><a id="citeref-oneapi" href="#footnote-oneapi">[oneapi]</a></sup></td></tr><tr><td style="text-align: right">Block sparse</td><td style="text-align: right">✓<sup class="footnote-reference"><a id="citeref-blocksparse" href="#footnote-blocksparse">[blocksparse]</a></sup></td><td style="text-align: right">✓<sup class="footnote-reference"><a id="citeref-blocksparse" href="#footnote-blocksparse">[blocksparse]</a></sup></td><td style="text-align: right">✓<sup class="footnote-reference"><a id="citeref-blocksparse" href="#footnote-blocksparse">[blocksparse]</a></sup></td><td style="text-align: right">✓<sup class="footnote-reference"><a id="citeref-blocksparse" href="#footnote-blocksparse">[blocksparse]</a></sup></td><td style="text-align: right">N/A<sup class="footnote-reference"><a id="citeref-oneapi" href="#footnote-oneapi">[oneapi]</a></sup></td></tr></table><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-linalg"><a class="tag is-link" href="#citeref-linalg">linalg</a>Some GPU vendors have not implemented certain matrix factorizations, or the ones they have implemented are not efficient compared to running on CPU, so as a workaround we perform those operations on CPU by transferring the data back and forth from GPU to CPU. We will add support for running those operations on GPU as they become available. If your algorithm&#39;s cost is dominated by those operations you won&#39;t see any speedup by trying to run it on those kinds of GPUs.</li><li class="footnote" id="footnote-blocksparse"><a class="tag is-link" href="#citeref-blocksparse">blocksparse</a>Support is experimental. Operations may not be fully optimized and could have bugs.</li><li class="footnote" id="footnote-oneapi"><a class="tag is-link" href="#citeref-oneapi">oneapi</a>We plan to add Intel GPU support through Julia&#39;s oneAPI.jl interface but don&#39;t have any Intel GPUs to test on right now.</li><li class="footnote" id="footnote-metal"><a class="tag is-link" href="#citeref-metal">metal</a>Apple doesn&#39;t support double precision floating point operations on their GPUs, see Section 2.1 of the <a href="https://developer.apple.com/metal/Metal-Shading-Language-Specification.pdf">Metal Shading Language Specification</a>. Until it does, we can&#39;t support double precision operations on Apple GPUs.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="Multithreading.html">« Multithreading</a><a class="docs-footer-nextpage" href="QNTricks.html">Symmetric (QN conserving) tensors: background and usage »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Saturday 9 November 2024 16:49">Saturday 9 November 2024</span>. Using Julia version 1.11.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
